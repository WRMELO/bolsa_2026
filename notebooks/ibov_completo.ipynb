{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6539e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== PROVEDOR E TENTATIVAS ========\n",
      "{\n",
      "  \"provider_used\": \"yahoo-chart\",\n",
      "  \"rows_returned\": 3399\n",
      "}\n",
      "[\n",
      "  {\n",
      "    \"provider\": \"yahoo-chart\",\n",
      "    \"attempt\": 1,\n",
      "    \"ok\": true,\n",
      "    \"rows\": 3399,\n",
      "    \"exception_message\": null\n",
      "  }\n",
      "]\n",
      "\n",
      "======== SCHEMA (EXATO) ========\n",
      "{\n",
      "  \"columns_expected\": [\n",
      "    \"date\",\n",
      "    \"open\",\n",
      "    \"high\",\n",
      "    \"low\",\n",
      "    \"close\",\n",
      "    \"volume\",\n",
      "    \"ticker\"\n",
      "  ],\n",
      "  \"columns_obtained\": [\n",
      "    \"date\",\n",
      "    \"open\",\n",
      "    \"high\",\n",
      "    \"low\",\n",
      "    \"close\",\n",
      "    \"volume\",\n",
      "    \"ticker\"\n",
      "  ],\n",
      "  \"dtypes_obtained\": {\n",
      "    \"date\": \"datetime64[ns]\",\n",
      "    \"open\": \"float64\",\n",
      "    \"high\": \"float64\",\n",
      "    \"low\": \"float64\",\n",
      "    \"close\": \"float64\",\n",
      "    \"volume\": \"int64\",\n",
      "    \"ticker\": \"string\"\n",
      "  },\n",
      "  \"nulls_percent\": {\n",
      "    \"date\": 0.0,\n",
      "    \"open\": 0.0,\n",
      "    \"high\": 0.0,\n",
      "    \"low\": 0.0,\n",
      "    \"close\": 0.0,\n",
      "    \"volume\": 0.0,\n",
      "    \"ticker\": 0.0\n",
      "  },\n",
      "  \"ticker_dtype_is_string\": true,\n",
      "  \"ticker_nulls_percent\": 0.0\n",
      "}\n",
      "\n",
      "======== INTERVALO TEMPORAL (com tolerâncias) ========\n",
      "{\n",
      "  \"required_start\": \"2012-01-01 00:00:00\",\n",
      "  \"start_tolerance_max\": \"2012-01-06 00:00:00\",\n",
      "  \"required_end_min\": \"2025-09-15 00:00:00\",\n",
      "  \"date_min\": \"2012-01-03 00:00:00\",\n",
      "  \"date_max\": \"2025-09-18 00:00:00\",\n",
      "  \"start_verdict\": \"OK\",\n",
      "  \"end_verdict\": \"OK\"\n",
      "}\n",
      "\n",
      "======== QUALIDADE ========\n",
      "{\n",
      "  \"percent_nulls\": {\n",
      "    \"date\": 0.0,\n",
      "    \"open\": 0.0,\n",
      "    \"high\": 0.0,\n",
      "    \"low\": 0.0,\n",
      "    \"close\": 0.0,\n",
      "    \"volume\": 0.0,\n",
      "    \"ticker\": 0.0\n",
      "  },\n",
      "  \"duplicates_by_date\": 0,\n",
      "  \"constraints\": {\n",
      "    \"nulls_must_be_zero_in\": {\n",
      "      \"date\": true,\n",
      "      \"close\": true,\n",
      "      \"ticker\": true\n",
      "    },\n",
      "    \"duplicates_by_date_must_be_zero\": true,\n",
      "    \"min_rows_required\": 2500,\n",
      "    \"date_monotonic_increasing\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "======== AMOSTRA — HEAD(10) ========\n",
      "      date   close  volume ticker\n",
      "2012-01-03 59265.0 3083000  ^BVSP\n",
      "2012-01-04 59365.0 2252000  ^BVSP\n",
      "2012-01-05 58546.0 2351200  ^BVSP\n",
      "2012-01-06 58600.0 1659200  ^BVSP\n",
      "2012-01-09 59083.0 2244600  ^BVSP\n",
      "2012-01-10 59806.0 2689200  ^BVSP\n",
      "2012-01-11 59962.0 2245200  ^BVSP\n",
      "2012-01-12 59921.0 2145600  ^BVSP\n",
      "2012-01-13 59147.0 5624200  ^BVSP\n",
      "2012-01-16 59956.0 1705000  ^BVSP\n",
      "\n",
      "======== AMOSTRA — TAIL(10) ========\n",
      "      date         close  volume ticker\n",
      "2025-09-05 142640.000000 8379400  ^BVSP\n",
      "2025-09-08 141792.000000 7440900  ^BVSP\n",
      "2025-09-09 141618.000000 7481900  ^BVSP\n",
      "2025-09-10 142349.000000 7138700  ^BVSP\n",
      "2025-09-11 143151.000000 7570400  ^BVSP\n",
      "2025-09-12 142272.000000 6388600  ^BVSP\n",
      "2025-09-15 143547.000000 6614000  ^BVSP\n",
      "2025-09-16 144062.000000 8478200  ^BVSP\n",
      "2025-09-17 145594.000000 9604400  ^BVSP\n",
      "2025-09-18 145437.265625       0  ^BVSP\n",
      "\n",
      "======== CONTAGENS ========\n",
      "{\n",
      "  \"rows_before_cleaning\": 3407,\n",
      "  \"rows_dropped_ohlc\": 8,\n",
      "  \"rows_after_cleaning\": 3399,\n",
      "  \"unique_days\": 3399,\n",
      "  \"days_with_volume_zero\": 32,\n",
      "  \"final_rows\": 3399\n",
      "}\n",
      "\n",
      "======== PLANO DE PERSISTÊNCIA (SIMULADO) ========\n",
      "{\n",
      "  \"dry_run\": false,\n",
      "  \"parquet_target\": \"/home/wrm/BOLSA_2026/bronze/IBOV.parquet\",\n",
      "  \"partitions\": [\n",
      "    \"year=2012\",\n",
      "    \"year=2013\",\n",
      "    \"year=2014\",\n",
      "    \"year=2015\",\n",
      "    \"year=2016\",\n",
      "    \"year=2017\",\n",
      "    \"year=2018\",\n",
      "    \"year=2019\",\n",
      "    \"year=2020\",\n",
      "    \"year=2021\",\n",
      "    \"year=2022\",\n",
      "    \"year=2023\",\n",
      "    \"year=2024\",\n",
      "    \"year=2025\"\n",
      "  ],\n",
      "  \"manifesto_path\": \"/home/wrm/BOLSA_2026/manifestos/bronze_ibov_manifesto.csv\",\n",
      "  \"manifesto_header\": \"timestamp,ticker,rows_total,date_min,date_max,columns_json,partitions_json,target_path\",\n",
      "  \"manifesto_row_sample\": \"2025-09-18T17:15:23.149334-03:00,^BVSP,3399,2012-01-03 00:00:00,2025-09-18 00:00:00,[\\\"date\\\", \\\"open\\\", \\\"high\\\", \\\"low\\\", \\\"close\\\", \\\"volume\\\", \\\"ticker\\\"],[\\\"year=2012\\\", \\\"year=2013\\\", \\\"year=2014\\\", \\\"year=2015\\\", \\\"year=2016\\\", \\\"year=2017\\\", \\\"year=2018\\\", \\\"year=2019\\\", \\\"year=2020\\\", \\\"year=2021\\\", \\\"year=2022\\\", \\\"year=2023\\\", \\\"year=2024\\\", \\\"year=2025\\\"],/home/wrm/BOLSA_2026/bronze/IBOV.parquet\",\n",
      "  \"nota\": \"Nenhuma escrita realizada em dry_run=True.\"\n",
      "}\n",
      "\n",
      "======== CHECKLIST ========\n",
      "{\n",
      "  \"provider_attempts_listed\": \"ok\",\n",
      "  \"schema_columns_and_dtypes_exact\": \"ok\",\n",
      "  \"interval_tolerance_verdicts\": \"ok\",\n",
      "  \"quality_nulls_and_duplicates\": \"ok\",\n",
      "  \"sample_head_tail_presented\": \"ok\",\n",
      "  \"counts_included\": \"ok\",\n",
      "  \"persistence_plan_simulated\": \"ok\"\n",
      "}\n",
      "\n",
      "======== ESTRUTURA DO RESULTADO (info) ========\n",
      "{\n",
      "  \"ticker\": \"^BVSP\",\n",
      "  \"periodo\": {\n",
      "    \"start\": \"2012-01-01 00:00:00\",\n",
      "    \"end\": \"2025-09-18 00:00:00\"\n",
      "  },\n",
      "  \"dry_run\": false,\n",
      "  \"timestamp_execucao\": \"2025-09-18T17:15:23.149334-03:00\",\n",
      "  \"dataframe_name\": \"bronze_ibov\",\n",
      "  \"columns\": [\n",
      "    \"date\",\n",
      "    \"open\",\n",
      "    \"high\",\n",
      "    \"low\",\n",
      "    \"close\",\n",
      "    \"volume\",\n",
      "    \"ticker\"\n",
      "  ],\n",
      "  \"dtypes\": {\n",
      "    \"date\": \"datetime64[ns]\",\n",
      "    \"open\": \"float64\",\n",
      "    \"high\": \"float64\",\n",
      "    \"low\": \"float64\",\n",
      "    \"close\": \"float64\",\n",
      "    \"volume\": \"int64\",\n",
      "    \"ticker\": \"string\"\n",
      "  },\n",
      "  \"provider_used\": \"yahoo-chart\",\n",
      "  \"status\": \"sucesso\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Instrução 1A-REV3 — Coleta direta Yahoo Chart → Bronze (dry_run)\n",
    "# Regras:\n",
    "# - Bloco único, auto-contido.\n",
    "# - dry_run=True (sem persistência).\n",
    "# - Provedores em ordem: Yahoo Chart -> yfinance -> Stooq.\n",
    "# - Sem dados sintéticos.\n",
    "# - Mensagens normativas: VALIDATION_ERROR / CHECKLIST_FAILURE.\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import BusinessDay as BDay\n",
    "\n",
    "# =========================\n",
    "# Parâmetros\n",
    "# =========================\n",
    "ROOT_DIR = Path(\"/home/wrm/BOLSA_2026\").resolve()\n",
    "DRY_RUN = False\n",
    "TICKER = \"^BVSP\"\n",
    "\n",
    "START_DATE_UTC = pd.Timestamp(\"2012-01-01\", tz=\"UTC\")\n",
    "NOW_UTC = pd.Timestamp(datetime.now(timezone.utc))\n",
    "END_DATE_UTC = NOW_UTC.normalize()  # 00:00 UTC de hoje\n",
    "PERIOD2_NOW_UTC = NOW_UTC  # para Yahoo Chart, usar timestamp \"agora\"\n",
    "\n",
    "PARQUET_TARGET = ROOT_DIR / \"bronze\" / \"IBOV.parquet\"\n",
    "MANIFESTO_TARGET = ROOT_DIR / \"manifestos\" / \"bronze_ibov_manifesto.csv\"\n",
    "\n",
    "EXPECTED_COLUMNS = [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"ticker\"]\n",
    "EXPECTED_DTYPES = {\n",
    "    \"date\": \"datetime64[ns]\",\n",
    "    \"open\": \"float64\",\n",
    "    \"high\": \"float64\",\n",
    "    \"low\": \"float64\",\n",
    "    \"close\": \"float64\",\n",
    "    \"volume\": \"int64\",\n",
    "    \"ticker\": \"string\",\n",
    "}\n",
    "\n",
    "AGORA = datetime.now().astimezone()\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def print_section(title: str):\n",
    "    print(\"\\n\" + \"=\" * 8 + f\" {title} \" + \"=\" * 8)\n",
    "\n",
    "def dtypes_signature(df: pd.DataFrame) -> Dict[str, str]:\n",
    "    return {c: str(df.dtypes[c]) for c in df.columns}\n",
    "\n",
    "def percent_nulls(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    total = len(df)\n",
    "    if total == 0:\n",
    "        return {c: 100.0 for c in df.columns}\n",
    "    return {c: float(df[c].isna().sum()) * 100.0 / float(total) for c in df.columns}\n",
    "\n",
    "def to_unix_seconds(ts: pd.Timestamp) -> int:\n",
    "    if ts.tzinfo is None:\n",
    "        ts = ts.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        ts = ts.tz_convert(\"UTC\")\n",
    "    return int(ts.timestamp())\n",
    "\n",
    "def bronze_normalize(\n",
    "    df_pre: pd.DataFrame,\n",
    "    ticker: str,\n",
    "    start_utc: pd.Timestamp,\n",
    "    end_utc: pd.Timestamp\n",
    ") -> Tuple[pd.DataFrame, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    df_pre: espera colunas ['date','open','high','low','close','volume'] (date pode ser datetime ou epoch já convertido)\n",
    "    Retorna df_final no schema Bronze + contagens de limpeza.\n",
    "    \"\"\"\n",
    "    df = df_pre.copy()\n",
    "\n",
    "    # Garantir colunas\n",
    "    for c in [\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "        if c not in df.columns:\n",
    "            raise RuntimeError(f\"SCHEMA_ERROR: coluna ausente em df_pre: {c}\")\n",
    "\n",
    "    # Date -> datetime naive normalizado 00:00\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True).dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "    # Tipos numéricos\n",
    "    for c in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Contagens antes da limpeza\n",
    "    rows_before_cleaning = int(len(df))\n",
    "\n",
    "    # Remover linhas com qualquer OHLC nulo\n",
    "    mask_ohlc_notna = (~df[\"open\"].isna()) & (~df[\"high\"].isna()) & (~df[\"low\"].isna()) & (~df[\"close\"].isna())\n",
    "    df = df[mask_ohlc_notna].copy()\n",
    "    rows_after_cleaning = int(len(df))\n",
    "    rows_dropped_ohlc = int(rows_before_cleaning - rows_after_cleaning)\n",
    "\n",
    "    # Volume: NaN -> 0, int64\n",
    "    df[\"volume\"] = pd.to_numeric(df[\"volume\"], errors=\"coerce\").fillna(0).astype(\"int64\")\n",
    "\n",
    "    # Forçar dtype float64 para OHLC\n",
    "    for c in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        df[c] = df[c].astype(\"float64\")\n",
    "\n",
    "    # ticker\n",
    "    df[\"ticker\"] = pd.Series([ticker] * len(df), dtype=\"string\").astype(\"string\")\n",
    "\n",
    "    # Filtrar intervalo [start, end]\n",
    "    start_naive = start_utc.tz_convert(None).tz_localize(None) if start_utc.tzinfo is not None else start_utc\n",
    "    end_naive = end_utc.tz_convert(None).tz_localize(None) if end_utc.tzinfo is not None else end_utc\n",
    "    df = df[(df[\"date\"] >= start_naive) & (df[\"date\"] <= end_naive)].copy()\n",
    "\n",
    "    # Ordenar, deduplicar por date\n",
    "    df = df.sort_values(\"date\").drop_duplicates(subset=[\"date\"], keep=\"last\").reset_index(drop=True)\n",
    "\n",
    "    # Reordenar colunas\n",
    "    df = df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"ticker\"]]\n",
    "\n",
    "    stats = {\n",
    "        \"rows_before_cleaning\": rows_before_cleaning,\n",
    "        \"rows_after_cleaning\": rows_after_cleaning,\n",
    "        \"rows_dropped_ohlc\": rows_dropped_ohlc,\n",
    "    }\n",
    "    return df, stats\n",
    "\n",
    "# =========================\n",
    "# Provedores\n",
    "# =========================\n",
    "def fetch_yahoo_chart_direct(\n",
    "    ticker: str,\n",
    "    start_utc: pd.Timestamp,\n",
    "    period2_now_utc: pd.Timestamp,\n",
    "    retries: int = 2,\n",
    "    backoff_seconds: List[float] = [0.8, 1.6]\n",
    ") -> Tuple[Optional[pd.DataFrame], Dict[str, int], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Coleta direto do endpoint Chart do Yahoo.\n",
    "    Retorna (df_final, stats, attempts).\n",
    "    \"\"\"\n",
    "    attempts: List[Dict[str, Any]] = []\n",
    "    df_final: Optional[pd.DataFrame] = None\n",
    "    stats: Dict[str, int] = {\"rows_before_cleaning\": 0, \"rows_after_cleaning\": 0, \"rows_dropped_ohlc\": 0}\n",
    "\n",
    "    base_url = \"https://query2.finance.yahoo.com/v8/finance/chart/%5EBVSP\"\n",
    "    params = {\n",
    "        \"period1\": str(to_unix_seconds(start_utc)),\n",
    "        \"period2\": str(to_unix_seconds(period2_now_utc)),\n",
    "        \"interval\": \"1d\",\n",
    "        \"events\": \"history\",\n",
    "        \"includeAdjustedClose\": \"false\",\n",
    "    }\n",
    "\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            # Prefer requests se disponível; caso contrário, urllib\n",
    "            try:\n",
    "                import requests  # type: ignore\n",
    "                r = requests.get(base_url, params=params, headers={\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) Python\"}, timeout=5)\n",
    "                status_code = r.status_code\n",
    "                if status_code < 200 or status_code >= 400:\n",
    "                    raise RuntimeError(f\"HTTP_STATUS_{status_code}\")\n",
    "                data = r.json()\n",
    "            except Exception as e_req:\n",
    "                # fallback para urllib\n",
    "                try:\n",
    "                    from urllib.parse import urlencode\n",
    "                    from urllib.request import Request, urlopen\n",
    "                    url = base_url + \"?\" + urlencode(params)\n",
    "                    req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) Python\"})\n",
    "                    with urlopen(req, timeout=6) as resp:\n",
    "                        status_code = getattr(resp, \"status\", 200)\n",
    "                        raw = resp.read()\n",
    "                    data = json.loads(raw.decode(\"utf-8\"))\n",
    "                except Exception as e_url:\n",
    "                    raise RuntimeError(f\"HTTP_ERROR: {e_req} | URLLIB_FALLBACK: {e_url}\")\n",
    "\n",
    "            # Parse esperado\n",
    "            if \"chart\" not in data:\n",
    "                raise RuntimeError(\"PARSE_ERROR: chave 'chart' ausente\")\n",
    "            chart = data[\"chart\"]\n",
    "            if chart.get(\"error\"):\n",
    "                raise RuntimeError(f\"REMOTE_ERROR: {chart.get('error')}\")\n",
    "            results = chart.get(\"result\", [])\n",
    "            if not results:\n",
    "                raise RuntimeError(\"PARSE_ERROR: 'result' vazio\")\n",
    "            res0 = results[0]\n",
    "            ts = res0.get(\"timestamp\", [])\n",
    "            inds = res0.get(\"indicators\", {})\n",
    "            quotes = inds.get(\"quote\", [])\n",
    "            if not quotes:\n",
    "                raise RuntimeError(\"PARSE_ERROR: 'quote[0]' ausente\")\n",
    "            q0 = quotes[0]\n",
    "            opens = q0.get(\"open\", [])\n",
    "            highs = q0.get(\"high\", [])\n",
    "            lows = q0.get(\"low\", [])\n",
    "            closes = q0.get(\"close\", [])\n",
    "            vols = q0.get(\"volume\", [])\n",
    "\n",
    "            n = min(len(ts), len(opens), len(highs), len(lows), len(closes), len(vols))\n",
    "            if n == 0:\n",
    "                raise RuntimeError(\"DATA_EMPTY_ERROR: listas vazias\")\n",
    "            # Construir DataFrame posicional\n",
    "            df_pre = pd.DataFrame({\n",
    "                \"date\": pd.to_datetime(ts[:n], unit=\"s\", utc=True),\n",
    "                \"open\": opens[:n],\n",
    "                \"high\": highs[:n],\n",
    "                \"low\": lows[:n],\n",
    "                \"close\": closes[:n],\n",
    "                \"volume\": vols[:n],\n",
    "            })\n",
    "            # Normalizar Bronze com limpeza\n",
    "            df_norm, stats = bronze_normalize(df_pre, ticker, START_DATE_UTC, END_DATE_UTC)\n",
    "            attempts.append({\"provider\": \"yahoo-chart\", \"attempt\": i + 1, \"ok\": True, \"rows\": int(len(df_norm)), \"exception_message\": None})\n",
    "            df_final = df_norm\n",
    "            return df_final, stats, attempts\n",
    "        except Exception as e:\n",
    "            attempts.append({\"provider\": \"yahoo-chart\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": str(e)})\n",
    "            if i < retries - 1:\n",
    "                time.sleep(backoff_seconds[min(i, len(backoff_seconds) - 1)])\n",
    "\n",
    "    return None, stats, attempts\n",
    "\n",
    "def fetch_with_yfinance(\n",
    "    ticker: str,\n",
    "    start_utc: pd.Timestamp,\n",
    "    end_utc: pd.Timestamp,\n",
    "    retries: int = 2,\n",
    "    backoff_seconds: List[float] = [0.8, 1.6]\n",
    ") -> Tuple[Optional[pd.DataFrame], Dict[str, int], List[Dict[str, Any]]]:\n",
    "    attempts: List[Dict[str, Any]] = []\n",
    "    stats: Dict[str, int] = {\"rows_before_cleaning\": 0, \"rows_after_cleaning\": 0, \"rows_dropped_ohlc\": 0}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            try:\n",
    "                import yfinance as yf  # type: ignore\n",
    "            except Exception as e_imp:\n",
    "                attempts.append({\"provider\": \"yfinance\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": f\"IMPORT_ERROR: {e_imp}\"})\n",
    "                break\n",
    "            try:\n",
    "                start_str = start_utc.tz_localize(None).date().isoformat() if start_utc.tzinfo else start_utc.date().isoformat()\n",
    "                end_inc = (end_utc + pd.Timedelta(days=1))  # end-exclusive\n",
    "                end_str = end_inc.tz_localize(None).date().isoformat() if end_inc.tzinfo else end_inc.date().isoformat()\n",
    "                df_raw = yf.download(\n",
    "                    tickers=ticker,\n",
    "                    start=start_str,\n",
    "                    end=end_str,\n",
    "                    interval=\"1d\",\n",
    "                    auto_adjust=False,\n",
    "                    progress=False,\n",
    "                    threads=True\n",
    "                )\n",
    "                if df_raw is None or df_raw.empty:\n",
    "                    raise RuntimeError(\"DATA_EMPTY_ERROR: yfinance retornou vazio\")\n",
    "                # Mapear colunas\n",
    "                df_raw = df_raw.copy()\n",
    "                # Lidar com MultiIndex simples: se colunas são ('Open',), etc.\n",
    "                if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "                    try:\n",
    "                        df_raw.columns = [c[-1] if isinstance(c, tuple) else c for c in df_raw.columns.to_list()]\n",
    "                    except Exception:\n",
    "                        df_raw.columns = df_raw.columns.get_level_values(-1)\n",
    "                rename_map = {\"Open\": \"open\", \"High\": \"high\", \"Low\": \"low\", \"Close\": \"close\", \"Volume\": \"volume\",\n",
    "                              \"open\": \"open\", \"high\": \"high\", \"low\": \"low\", \"close\": \"close\", \"volume\": \"volume\"}\n",
    "                df_raw = df_raw.rename(columns=rename_map)\n",
    "                need = {\"open\", \"high\", \"low\", \"close\", \"volume\"}\n",
    "                if not need.issubset(set(df_raw.columns)):\n",
    "                    missing = sorted(list(need - set(df_raw.columns)))\n",
    "                    raise RuntimeError(f\"SCHEMA_ERROR: faltam colunas em yfinance: {missing}\")\n",
    "                df_pre = df_raw.reset_index().rename(columns={\"Date\": \"date\", \"Datetime\": \"date\"})\n",
    "                if \"date\" not in df_pre.columns:\n",
    "                    # se índice for datetime e não houver 'date' após reset\n",
    "                    df_pre = df_raw.copy()\n",
    "                    df_pre[\"date\"] = df_pre.index\n",
    "                    df_pre = df_pre.reset_index(drop=True)\n",
    "                df_pre = df_pre[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "                df_norm, stats = bronze_normalize(df_pre, ticker, START_DATE_UTC, END_DATE_UTC)\n",
    "                attempts.append({\"provider\": \"yfinance\", \"attempt\": i + 1, \"ok\": True, \"rows\": int(len(df_norm)), \"exception_message\": None})\n",
    "                return df_norm, stats, attempts\n",
    "            except Exception as e_dl:\n",
    "                attempts.append({\"provider\": \"yfinance\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": str(e_dl)})\n",
    "                if i < retries - 1:\n",
    "                    time.sleep(backoff_seconds[min(i, len(backoff_seconds) - 1)])\n",
    "        except Exception as e:\n",
    "            attempts.append({\"provider\": \"yfinance\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": str(e)})\n",
    "            break\n",
    "    return None, stats, attempts\n",
    "\n",
    "def fetch_with_stooq(\n",
    "    ticker: str,\n",
    "    start_utc: pd.Timestamp,\n",
    "    end_utc: pd.Timestamp,\n",
    "    retries: int = 1\n",
    ") -> Tuple[Optional[pd.DataFrame], Dict[str, int], List[Dict[str, Any]]]:\n",
    "    attempts: List[Dict[str, Any]] = []\n",
    "    stats: Dict[str, int] = {\"rows_before_cleaning\": 0, \"rows_after_cleaning\": 0, \"rows_dropped_ohlc\": 0}\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            try:\n",
    "                from pandas_datareader import data as dr  # type: ignore\n",
    "            except Exception as e_imp:\n",
    "                attempts.append({\"provider\": \"stooq\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": f\"IMPORT_ERROR: {e_imp}\"})\n",
    "                break\n",
    "            try:\n",
    "                candidates = [ticker, ticker.replace(\"^\", \"\"), ticker.replace(\"^\", \"\").lower()]\n",
    "                df_raw = None\n",
    "                last_exc = None\n",
    "                for tk in candidates:\n",
    "                    try:\n",
    "                        df_raw = dr.DataReader(tk, \"stooq\", start=start_utc.tz_localize(None), end=end_utc.tz_localize(None))\n",
    "                        if df_raw is not None and not df_raw.empty:\n",
    "                            break\n",
    "                    except Exception as e2:\n",
    "                        last_exc = e2\n",
    "                        continue\n",
    "                if df_raw is None or df_raw.empty:\n",
    "                    raise RuntimeError(f\"STOOQ_EMPTY: {last_exc}\") if last_exc else RuntimeError(\"STOOQ_EMPTY: retorno vazio\")\n",
    "                # Stooq costuma vir com colunas minúsculas ou 'Open/High/...'\n",
    "                df_raw = df_raw.sort_index()\n",
    "                if isinstance(df_raw.columns, pd.MultiIndex):\n",
    "                    try:\n",
    "                        df_raw.columns = [c[-1] if isinstance(c, tuple) else c for c in df_raw.columns.to_list()]\n",
    "                    except Exception:\n",
    "                        df_raw.columns = df_raw.columns.get_level_values(-1)\n",
    "                rename_map = {\"Open\": \"open\", \"High\": \"high\", \"Low\": \"low\", \"Close\": \"close\", \"Volume\": \"volume\",\n",
    "                              \"open\": \"open\", \"high\": \"high\", \"low\": \"low\", \"close\": \"close\", \"volume\": \"volume\"}\n",
    "                df_raw = df_raw.rename(columns=rename_map)\n",
    "                need = {\"open\", \"high\", \"low\", \"close\", \"volume\"}\n",
    "                if not need.issubset(set(df_raw.columns)):\n",
    "                    missing = sorted(list(need - set(df_raw.columns)))\n",
    "                    raise RuntimeError(f\"SCHEMA_ERROR: faltam colunas em stooq: {missing}\")\n",
    "                df_pre = df_raw.copy()\n",
    "                df_pre[\"date\"] = df_pre.index\n",
    "                df_pre = df_pre.reset_index(drop=True)\n",
    "                df_pre = df_pre[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "                df_norm, stats = bronze_normalize(df_pre, ticker, START_DATE_UTC, END_DATE_UTC)\n",
    "                attempts.append({\"provider\": \"stooq\", \"attempt\": i + 1, \"ok\": True, \"rows\": int(len(df_norm)), \"exception_message\": None})\n",
    "                return df_norm, stats, attempts\n",
    "            except Exception as e_dl:\n",
    "                attempts.append({\"provider\": \"stooq\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": str(e_dl)})\n",
    "                break\n",
    "        except Exception as e:\n",
    "            attempts.append({\"provider\": \"stooq\", \"attempt\": i + 1, \"ok\": False, \"rows\": 0, \"exception_message\": str(e)})\n",
    "            break\n",
    "    return None, stats, attempts\n",
    "\n",
    "# =========================\n",
    "# Validações & Plano\n",
    "# =========================\n",
    "def validate_schema(df: pd.DataFrame) -> List[str]:\n",
    "    erros = []\n",
    "    if list(df.columns) != EXPECTED_COLUMNS:\n",
    "        erros.append(f\"VALIDATION_ERROR: schema de colunas incorreto. Esperado={EXPECTED_COLUMNS} Obtido={list(df.columns)}\")\n",
    "    dts = dtypes_signature(df)\n",
    "    for c, dt_expected in EXPECTED_DTYPES.items():\n",
    "        if c not in dts:\n",
    "            erros.append(f\"VALIDATION_ERROR: coluna ausente no DataFrame: {c}\")\n",
    "            continue\n",
    "        got = dts[c]\n",
    "        if c == \"ticker\":\n",
    "            if not got.startswith(\"string\"):\n",
    "                erros.append(f\"VALIDATION_ERROR: dtype incorreto para ticker. Esperado=string Obtido={got}\")\n",
    "        else:\n",
    "            if got != dt_expected:\n",
    "                erros.append(f\"VALIDATION_ERROR: dtype incorreto para {c}. Esperado={dt_expected} Obtido={got}\")\n",
    "    if df[\"ticker\"].isna().any():\n",
    "        erros.append(\"VALIDATION_ERROR: ticker contém valores nulos (deve ser 0%).\")\n",
    "    return erros\n",
    "\n",
    "def validate_quality(df: pd.DataFrame) -> List[str]:\n",
    "    erros = []\n",
    "    if len(df) < 2500:\n",
    "        erros.append(f\"VALIDATION_ERROR: cobertura insuficiente — linhas={len(df)} (< 2500)\")\n",
    "    pn = percent_nulls(df)\n",
    "    for col in [\"date\", \"close\", \"ticker\"]:\n",
    "        if round(pn.get(col, 100.0), 6) != 0.0:\n",
    "            erros.append(f\"VALIDATION_ERROR: % nulos em {col} deve ser 0%, obtido={pn.get(col, 100.0):.6f}%\")\n",
    "    dups = int(df.duplicated(subset=[\"date\"]).sum())\n",
    "    if dups != 0:\n",
    "        erros.append(f\"VALIDATION_ERROR: duplicatas por date detectadas (= {dups})\")\n",
    "    if not df[\"date\"].is_monotonic_increasing:\n",
    "        erros.append(\"VALIDATION_ERROR: coluna date não é monotônica crescente.\")\n",
    "    return erros\n",
    "\n",
    "def validate_interval_with_tolerance(df: pd.DataFrame, start_utc: pd.Timestamp) -> Tuple[List[str], Dict[str, Any]]:\n",
    "    erros = []\n",
    "    if df.empty:\n",
    "        return [\"VALIDATION_ERROR: DataFrame vazio após ingestão.\"], {\"date_min\": None, \"date_max\": None, \"start_verdict\": \"FAIL\", \"end_verdict\": \"FAIL\"}\n",
    "    dmin = pd.to_datetime(df[\"date\"].min())\n",
    "    dmax = pd.to_datetime(df[\"date\"].max())\n",
    "    required_start = start_utc.tz_convert(None).tz_localize(None) if start_utc.tzinfo else start_utc\n",
    "    start_tol_max = (required_start + BDay(5)).to_pydatetime().date()\n",
    "    start_ok = dmin <= pd.Timestamp(start_tol_max).to_pydatetime()\n",
    "    if not start_ok:\n",
    "        erros.append(f\"VALIDATION_ERROR: date.min ({dmin.date().isoformat()}) > tolerância de início ({start_tol_max.isoformat()})\")\n",
    "    required_end_min = (pd.Timestamp(datetime.now(timezone.utc)).normalize() - pd.Timedelta(days=3)).tz_localize(None)\n",
    "    end_ok = dmax >= required_end_min\n",
    "    if not end_ok:\n",
    "        erros.append(f\"VALIDATION_ERROR: date.max ({dmax.date().isoformat()}) < requerido mínimo ({required_end_min.date().isoformat()}) (tolerância 3 dias)\")\n",
    "    info = {\n",
    "        \"date_min\": dmin,\n",
    "        \"date_max\": dmax,\n",
    "        \"required_start\": required_start,\n",
    "        \"start_tolerance_max\": pd.Timestamp(start_tol_max),\n",
    "        \"required_end_min\": required_end_min,\n",
    "        \"start_verdict\": \"OK\" if start_ok else \"FAIL\",\n",
    "        \"end_verdict\": \"OK\" if end_ok else \"FAIL\",\n",
    "    }\n",
    "    return erros, info\n",
    "\n",
    "def build_persistence_plan(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    years = sorted(pd.to_datetime(df[\"date\"]).dt.year.unique().tolist())\n",
    "    partitions = [f\"year={y}\" for y in years]\n",
    "    manifesto_header = [\"timestamp\", \"ticker\", \"rows_total\", \"date_min\", \"date_max\", \"columns_json\", \"partitions_json\", \"target_path\"]\n",
    "    manifesto_row = [\n",
    "        AGORA.isoformat(),\n",
    "        TICKER,\n",
    "        int(len(df)),\n",
    "        str(pd.to_datetime(df[\"date\"]).min()),\n",
    "        str(pd.to_datetime(df[\"date\"]).max()),\n",
    "        json.dumps(EXPECTED_COLUMNS, ensure_ascii=False),\n",
    "        json.dumps(partitions, ensure_ascii=False),\n",
    "        str(PARQUET_TARGET),\n",
    "    ]\n",
    "    return {\n",
    "        \"parquet_target\": str(PARQUET_TARGET),\n",
    "        \"partitions\": partitions,\n",
    "        \"manifesto_path\": str(MANIFESTO_TARGET),\n",
    "        \"manifesto_header\": \",\".join(manifesto_header),\n",
    "        \"manifesto_row_sample\": \",\".join([str(x) for x in manifesto_row]),\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# Execução Principal\n",
    "# =========================\n",
    "def main():\n",
    "    provider_attempts: List[Dict[str, Any]] = []\n",
    "    erros_normativos: List[str] = []\n",
    "\n",
    "    bronze_ibov: Optional[pd.DataFrame] = None\n",
    "    used_provider: Optional[str] = None\n",
    "    cleaning_stats: Dict[str, int] = {\"rows_before_cleaning\": 0, \"rows_after_cleaning\": 0, \"rows_dropped_ohlc\": 0}\n",
    "\n",
    "    # P1: Yahoo Chart\n",
    "    df_yc, stats_yc, attempts_yc = fetch_yahoo_chart_direct(TICKER, START_DATE_UTC, PERIOD2_NOW_UTC)\n",
    "    provider_attempts.extend(attempts_yc)\n",
    "    if df_yc is not None and not df_yc.empty:\n",
    "        bronze_ibov = df_yc\n",
    "        used_provider = \"yahoo-chart\"\n",
    "        cleaning_stats = stats_yc\n",
    "    else:\n",
    "        # P2: yfinance (apenas se P1 falhar)\n",
    "        df_yf, stats_yf, attempts_yf = fetch_with_yfinance(TICKER, START_DATE_UTC, END_DATE_UTC)\n",
    "        provider_attempts.extend(attempts_yf)\n",
    "        if df_yf is not None and not df_yf.empty:\n",
    "            bronze_ibov = df_yf\n",
    "            used_provider = \"yfinance\"\n",
    "            cleaning_stats = stats_yf\n",
    "        else:\n",
    "            # P3: stooq (apenas se P1 e P2 falharem)\n",
    "            df_stq, stats_stq, attempts_stq = fetch_with_stooq(TICKER, START_DATE_UTC, END_DATE_UTC)\n",
    "            provider_attempts.extend(attempts_stq)\n",
    "            if df_stq is not None and not df_stq.empty:\n",
    "                bronze_ibov = df_stq\n",
    "                used_provider = \"stooq\"\n",
    "                cleaning_stats = stats_stq\n",
    "\n",
    "    # Se todos falharem\n",
    "    if bronze_ibov is None or bronze_ibov.empty:\n",
    "        print_section(\"PROVEDORES E TENTATIVAS\")\n",
    "        print(json.dumps(provider_attempts, ensure_ascii=False, indent=2))\n",
    "        # Selecionar a exceção mais informativa (última não-ok com mensagem)\n",
    "        last_err = None\n",
    "        for att in reversed(provider_attempts):\n",
    "            if not att.get(\"ok\") and att.get(\"exception_message\"):\n",
    "                last_err = att.get(\"exception_message\")\n",
    "                break\n",
    "        print(f\"VALIDATION_ERROR: PROVIDERS_EXHAUSTED — {last_err if last_err else 'sem mensagem detalhada.'}\")\n",
    "        print_section(\"CHECKLIST\")\n",
    "        checklist = {\n",
    "            \"provider_attempts_listed\": \"ok\",\n",
    "            \"schema_columns_and_dtypes_exact\": \"falha\",\n",
    "            \"interval_tolerance_verdicts\": \"falha\",\n",
    "            \"quality_nulls_and_duplicates\": \"falha\",\n",
    "            \"sample_head_tail_presented\": \"falha\",\n",
    "            \"counts_included\": \"falha\",\n",
    "            \"persistence_plan_simulated\": \"ok\",\n",
    "        }\n",
    "        print(json.dumps(checklist, ensure_ascii=False, indent=2))\n",
    "        for k, v in checklist.items():\n",
    "            if v != \"ok\":\n",
    "                print(f\"CHECKLIST_FAILURE: {k} não atendido.\")\n",
    "        print_section(\"DÚVIDAS OBJETIVAS\")\n",
    "        print(\"- Rede pode estar bloqueada para Yahoo/Stooq? Há Proxy que devamos configurar?\")\n",
    "        print(\"- Deseja fornecer outro provedor (AlphaVantage/Polygon) com chave?\")\n",
    "        print(\"- Autoriza aumentar timeouts/backoff e tentar novamente?\")\n",
    "        return\n",
    "\n",
    "    # Reforço de tipos/order e ticker\n",
    "    bronze_ibov = bronze_ibov.copy()\n",
    "    bronze_ibov[\"date\"] = pd.to_datetime(bronze_ibov[\"date\"], errors=\"coerce\").dt.normalize()\n",
    "    for c in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        bronze_ibov[c] = pd.to_numeric(bronze_ibov[c], errors=\"coerce\").astype(\"float64\")\n",
    "    bronze_ibov[\"volume\"] = pd.to_numeric(bronze_ibov[\"volume\"], errors=\"coerce\").fillna(0).astype(\"int64\")\n",
    "    bronze_ibov[\"ticker\"] = pd.Series([TICKER] * len(bronze_ibov), dtype=\"string\").astype(\"string\")\n",
    "    bronze_ibov = bronze_ibov[EXPECTED_COLUMNS].sort_values(\"date\").drop_duplicates(subset=[\"date\"], keep=\"last\").reset_index(drop=True)\n",
    "\n",
    "    # Validações\n",
    "    schema_errors = validate_schema(bronze_ibov)\n",
    "    qual_errors = validate_quality(bronze_ibov)\n",
    "    interval_errors, interval_info = validate_interval_with_tolerance(bronze_ibov, START_DATE_UTC)\n",
    "    erros_normativos.extend(schema_errors + qual_errors + interval_errors)\n",
    "\n",
    "    # Métricas\n",
    "    total_linhas = int(len(bronze_ibov))\n",
    "    dias_unicos = int(bronze_ibov[\"date\"].nunique()) if total_linhas > 0 else 0\n",
    "    dias_vol_zero = int((bronze_ibov[\"volume\"] == 0).sum()) if total_linhas > 0 else 0\n",
    "    pct_nulos = percent_nulls(bronze_ibov)\n",
    "    dups_by_date = int(bronze_ibov.duplicated(subset=[\"date\"]).sum())\n",
    "\n",
    "    # Plano de persistência (simulado)\n",
    "    persist_plan = build_persistence_plan(bronze_ibov)\n",
    "\n",
    "    # Relatórios\n",
    "    print_section(\"PROVEDOR E TENTATIVAS\")\n",
    "    print(json.dumps({\"provider_used\": used_provider, \"rows_returned\": total_linhas}, ensure_ascii=False, indent=2))\n",
    "    print(json.dumps(provider_attempts, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print_section(\"SCHEMA (EXATO)\")\n",
    "    schema_out = {\n",
    "        \"columns_expected\": EXPECTED_COLUMNS,\n",
    "        \"columns_obtained\": list(bronze_ibov.columns),\n",
    "        \"dtypes_obtained\": dtypes_signature(bronze_ibov),\n",
    "        \"nulls_percent\": {k: round(v, 6) for k, v in pct_nulos.items()},\n",
    "        \"ticker_dtype_is_string\": str(bronze_ibov.dtypes[\"ticker\"]).startswith(\"string\"),\n",
    "        \"ticker_nulls_percent\": round(pct_nulos.get(\"ticker\", 100.0), 6),\n",
    "    }\n",
    "    print(json.dumps(schema_out, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print_section(\"INTERVALO TEMPORAL (com tolerâncias)\")\n",
    "    interval_out = {\n",
    "        \"required_start\": str(interval_info[\"required_start\"]) if interval_info[\"date_min\"] is not None else None,\n",
    "        \"start_tolerance_max\": str(interval_info[\"start_tolerance_max\"]) if interval_info[\"date_min\"] is not None else None,\n",
    "        \"required_end_min\": str(interval_info[\"required_end_min\"]) if interval_info[\"date_max\"] is not None else None,\n",
    "        \"date_min\": str(pd.to_datetime(interval_info[\"date_min\"])) if interval_info[\"date_min\"] is not None else None,\n",
    "        \"date_max\": str(pd.to_datetime(interval_info[\"date_max\"])) if interval_info[\"date_max\"] is not None else None,\n",
    "        \"start_verdict\": interval_info.get(\"start_verdict\", \"FAIL\"),\n",
    "        \"end_verdict\": interval_info.get(\"end_verdict\", \"FAIL\"),\n",
    "    }\n",
    "    print(json.dumps(interval_out, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print_section(\"QUALIDADE\")\n",
    "    qualidade_out = {\n",
    "        \"percent_nulls\": {k: round(v, 6) for k, v in pct_nulos.items()},\n",
    "        \"duplicates_by_date\": dups_by_date,\n",
    "        \"constraints\": {\n",
    "            \"nulls_must_be_zero_in\": {\"date\": True, \"close\": True, \"ticker\": True},\n",
    "            \"duplicates_by_date_must_be_zero\": True,\n",
    "            \"min_rows_required\": 2500,\n",
    "            \"date_monotonic_increasing\": True\n",
    "        }\n",
    "    }\n",
    "    print(json.dumps(qualidade_out, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print_section(\"AMOSTRA — HEAD(10)\")\n",
    "    print(bronze_ibov[[\"date\", \"close\", \"volume\", \"ticker\"]].head(10).to_string(index=False))\n",
    "\n",
    "    print_section(\"AMOSTRA — TAIL(10)\")\n",
    "    print(bronze_ibov[[\"date\", \"close\", \"volume\", \"ticker\"]].tail(10).to_string(index=False))\n",
    "\n",
    "    print_section(\"CONTAGENS\")\n",
    "    print(json.dumps({\n",
    "        \"rows_before_cleaning\": cleaning_stats.get(\"rows_before_cleaning\", 0),\n",
    "        \"rows_dropped_ohlc\": cleaning_stats.get(\"rows_dropped_ohlc\", 0),\n",
    "        \"rows_after_cleaning\": cleaning_stats.get(\"rows_after_cleaning\", 0),\n",
    "        \"unique_days\": dias_unicos,\n",
    "        \"days_with_volume_zero\": dias_vol_zero,\n",
    "        \"final_rows\": total_linhas\n",
    "    }, ensure_ascii=False, indent=2))\n",
    "\n",
    "    print_section(\"PLANO DE PERSISTÊNCIA (SIMULADO)\")\n",
    "    print(json.dumps({\n",
    "        \"dry_run\": DRY_RUN,\n",
    "        \"parquet_target\": persist_plan[\"parquet_target\"],\n",
    "        \"partitions\": persist_plan[\"partitions\"],\n",
    "        \"manifesto_path\": persist_plan[\"manifesto_path\"],\n",
    "        \"manifesto_header\": persist_plan[\"manifesto_header\"],\n",
    "        \"manifesto_row_sample\": persist_plan[\"manifesto_row_sample\"],\n",
    "        \"nota\": \"Nenhuma escrita realizada em dry_run=True.\"\n",
    "    }, ensure_ascii=False, indent=2))\n",
    "\n",
    "    # Erros normativos (se houver)\n",
    "    if erros_normativos:\n",
    "        print_section(\"ERROS NORMATIVOS\")\n",
    "        seen = set()\n",
    "        ordered = []\n",
    "        for e in erros_normativos:\n",
    "            if e not in seen:\n",
    "                seen.add(e)\n",
    "                ordered.append(e)\n",
    "        for e in ordered:\n",
    "            if not (str(e).startswith(\"VALIDATION_ERROR\") or str(e).startswith(\"CHECKLIST_FAILURE\")):\n",
    "                print(f\"VALIDATION_ERROR: {e}\")\n",
    "            else:\n",
    "                print(e)\n",
    "\n",
    "    # Checklist\n",
    "    print_section(\"CHECKLIST\")\n",
    "    schema_ok = (len(schema_errors := schema_errors if 'schema_errors' in locals() else validate_schema(bronze_ibov)) == 0)  # revalida se necessário\n",
    "    interval_ok = (len(interval_errors) == 0 and interval_info.get(\"start_verdict\") == \"OK\" and interval_info.get(\"end_verdict\") == \"OK\")\n",
    "    quality_ok = (len(qual_errors := qual_errors if 'qual_errors' in locals() else validate_quality(bronze_ibov)) == 0)\n",
    "    sample_ok = (total_linhas > 0)\n",
    "    counts_ok = True  # contagens sempre apresentadas\n",
    "    attempts_ok = True\n",
    "    plan_ok = True\n",
    "\n",
    "    checklist = {\n",
    "        \"provider_attempts_listed\": \"ok\" if attempts_ok else \"falha\",\n",
    "        \"schema_columns_and_dtypes_exact\": \"ok\" if schema_ok else \"falha\",\n",
    "        \"interval_tolerance_verdicts\": \"ok\" if interval_ok else \"falha\",\n",
    "        \"quality_nulls_and_duplicates\": \"ok\" if quality_ok else \"falha\",\n",
    "        \"sample_head_tail_presented\": \"ok\" if sample_ok else \"falha\",\n",
    "        \"counts_included\": \"ok\" if counts_ok else \"falha\",\n",
    "        \"persistence_plan_simulated\": \"ok\" if plan_ok else \"falha\",\n",
    "    }\n",
    "    print(json.dumps(checklist, ensure_ascii=False, indent=2))\n",
    "    for k, v in checklist.items():\n",
    "        if v != \"ok\":\n",
    "            print(f\"CHECKLIST_FAILURE: {k} não atendido.\")\n",
    "\n",
    "    # Estrutura do Resultado (info)\n",
    "    print_section(\"ESTRUTURA DO RESULTADO (info)\")\n",
    "    resultado = {\n",
    "        \"ticker\": TICKER,\n",
    "        \"periodo\": {\"start\": str(START_DATE_UTC.tz_localize(None)), \"end\": str(END_DATE_UTC.tz_localize(None))},\n",
    "        \"dry_run\": DRY_RUN,\n",
    "        \"timestamp_execucao\": AGORA.isoformat(),\n",
    "        \"dataframe_name\": \"bronze_ibov\",\n",
    "        \"columns\": EXPECTED_COLUMNS,\n",
    "        \"dtypes\": dtypes_signature(bronze_ibov),\n",
    "        \"provider_used\": used_provider,\n",
    "        \"status\": \"sucesso\" if not erros_normativos and all(v == \"ok\" for v in checklist.values()) else \"falha\"\n",
    "    }\n",
    "    print(json.dumps(resultado, ensure_ascii=False, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Contrato\n",
    "    # - Coleta direta Yahoo Chart (requests/stdlib) → yfinance → stooq (sem dados sintéticos)\n",
    "    # - Normalização Bronze e validações: schema, qualidade, tolerâncias de calendário\n",
    "    # - Planos de persistência (simulados), checklist e mensagens normativas\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project: BOLSA_2026)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
