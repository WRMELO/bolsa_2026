{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7a41ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Partitions saved: /home/wrm/BOLSA_2026/gold/IBOV/partitions_ibov.csv\n",
      "WARNING: Not enough classes in training for horizon 1 block 1; skipping\n",
      "WARNING: Not enough classes in training for horizon 1 block 1; skipping\n",
      "WARNING: Not enough classes in training for horizon 3 block 1; skipping\n",
      "WARNING: Not enough classes in training for horizon 3 block 1; skipping\n",
      "WARNING: Not enough classes in training for horizon 5 block 1; skipping\n",
      "WARNING: Not enough classes in training for horizon 5 block 1; skipping\n",
      "INFO: Metrics saved: /home/wrm/BOLSA_2026/gold/IBOV/metrics_ibov_baseline.csv\n",
      "INFO: Thresholds saved: /home/wrm/BOLSA_2026/gold/IBOV/thresholds_tau_ibov.json\n",
      "INFO: Provenance appended: /home/wrm/BOLSA_2026/gold/IBOV/PROVENANCE_IBOV.txt\n",
      "INFO: Metrics saved: /home/wrm/BOLSA_2026/gold/IBOV/metrics_ibov_baseline.csv\n",
      "INFO: Thresholds saved: /home/wrm/BOLSA_2026/gold/IBOV/thresholds_tau_ibov.json\n",
      "INFO: Provenance appended: /home/wrm/BOLSA_2026/gold/IBOV/PROVENANCE_IBOV.txt\n"
     ]
    }
   ],
   "source": [
    "# Objetivo: Baseline XGBoost multiclasses (corrigido) com walk-forward, embargo e calibração.\n",
    "# Correção: agora padroniza rótulos usando LabelEncoder (0..K-1) antes de treinar/calibrar para evitar erro base_score.\n",
    "# Entradas/saídas e premissas iguais às versões anteriores.\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import hashlib\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "GOLD_DIR = Path(\"/home/wrm/BOLSA_2026/gold/IBOV\")\n",
    "GOLD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "GOLD_PARQUET = GOLD_DIR / \"gold_ibov_features.parquet\"\n",
    "PROV = GOLD_DIR / \"PROVENANCE_IBOV.txt\"\n",
    "\n",
    "# Outputs\n",
    "PARTITIONS_CSV = GOLD_DIR / \"partitions_ibov.csv\"\n",
    "METRICS_CSV = GOLD_DIR / \"metrics_ibov_baseline.csv\"\n",
    "THRESHOLDS_JSON = GOLD_DIR / \"thresholds_tau_ibov.json\"\n",
    "\n",
    "# Hyperparameters (conservative defaults) - removed use_label_encoder (deprecated/unused)\n",
    "HYPER = {\n",
    "    \"max_depth\": 4,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"n_estimators\": 400,\n",
    "    \"learning_rate\": 0.08,\n",
    "    \"random_state\": SEED,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "}\n",
    "\n",
    "EMBARGO = 5  # pregões\n",
    "\n",
    "def sha256_of_file(p: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with p.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_gold(p: Path) -> pd.DataFrame:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    df = pd.read_parquet(p)\n",
    "    return df\n",
    "\n",
    "def select_features(df: pd.DataFrame) -> dict:\n",
    "    banned_prefix = (\"r_d\", \"y_d\", \"k_d\")\n",
    "    banned_exact = {\"date\"}\n",
    "    banned_contains = {\"ticker\"}\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    features = [\n",
    "        c\n",
    "        for c in numeric_cols\n",
    "        if not any(c.startswith(bp) for bp in banned_prefix)\n",
    "        and c not in banned_exact\n",
    "        and not any(b in c.lower() for b in banned_contains)\n",
    "    ]\n",
    "    feat_map = {1: features, 3: features, 5: features}\n",
    "    return feat_map\n",
    "\n",
    "def make_partitions(df: pd.DataFrame, n_splits=5) -> pd.DataFrame:\n",
    "    dates = pd.to_datetime(df[\"date\"]).sort_values().unique()\n",
    "    n = len(dates)\n",
    "    k = min(max(4, n_splits), 6)\n",
    "    block_size = max(1, n // k)\n",
    "    partitions = []\n",
    "    for i in range(k):\n",
    "        test_start_idx = i * block_size\n",
    "        test_end_idx = min(n - 1, (i + 1) * block_size - 1) if i < k - 1 else n - 1\n",
    "        test_start = dates[test_start_idx]\n",
    "        test_end = dates[test_end_idx]\n",
    "\n",
    "        train_start = dates[0]\n",
    "        train_end = dates[max(0, test_start_idx - 1)]\n",
    "\n",
    "        embargo_start = dates[max(0, test_start_idx - EMBARGO)] if test_start_idx - EMBARGO >= 0 else train_end\n",
    "        embargo_end = train_end\n",
    "\n",
    "        partitions.append(\n",
    "            {\n",
    "                \"block_id\": i + 1,\n",
    "                \"train_start\": str(train_start.date()),\n",
    "                \"train_end\": str(train_end.date()),\n",
    "                \"embargo_start\": str(embargo_start.date()) if embargo_start is not None else None,\n",
    "                \"embargo_end\": str(embargo_end.date()) if embargo_end is not None else None,\n",
    "                \"test_start\": str(test_start.date()),\n",
    "                \"test_end\": str(test_end.date()),\n",
    "            }\n",
    "        )\n",
    "    pdf = pd.DataFrame(partitions)\n",
    "    pdf.to_csv(PARTITIONS_CSV, index=False)\n",
    "    logging.info(f\"Partitions saved: {PARTITIONS_CSV}\")\n",
    "    return pdf\n",
    "\n",
    "def train_and_evaluate(df: pd.DataFrame, feat_map: dict, partitions: pd.DataFrame):\n",
    "    metrics_rows = []\n",
    "    thresholds = {}\n",
    "    targets = {1: (0.45, 0.55), 3: (0.38, 0.45), 5: (0.30, 0.38)}\n",
    "\n",
    "    for h in (1, 3, 5):\n",
    "        features = feat_map[h]\n",
    "        (GOLD_DIR / f\"feature_list_d{h}.txt\").write_text(\"\\n\".join(features))\n",
    "        thresholds[h] = None\n",
    "\n",
    "        for _, row in partitions.iterrows():\n",
    "            bid = int(row[\"block_id\"])\n",
    "            # masks by date\n",
    "            test_mask = (\n",
    "                (pd.to_datetime(df[\"date\"]).dt.date >= pd.to_datetime(row[\"test_start\"]).date())\n",
    "                & (pd.to_datetime(df[\"date\"]).dt.date <= pd.to_datetime(row[\"test_end\"]).date())\n",
    "            )\n",
    "            train_mask = (\n",
    "                (pd.to_datetime(df[\"date\"]).dt.date >= pd.to_datetime(row[\"train_start\"]).date())\n",
    "                & (pd.to_datetime(df[\"date\"]).dt.date <= pd.to_datetime(row[\"train_end\"]).date())\n",
    "            )\n",
    "\n",
    "            X_train = df.loc[train_mask, features].copy()\n",
    "            y_train = df.loc[train_mask, f\"y_d{h}_cls\"].copy()\n",
    "            X_test = df.loc[test_mask, features].copy()\n",
    "            y_test = df.loc[test_mask, f\"y_d{h}_cls\"].copy()\n",
    "\n",
    "            if y_train.dropna().empty or y_test.dropna().empty:\n",
    "                logging.warning(f\"Empty train or test for horizon {h} block {bid}; skipping\")\n",
    "                continue\n",
    "\n",
    "            # compute class weight map on original labels\n",
    "            classes_orig = np.unique(y_train.dropna())\n",
    "            try:\n",
    "                cls_w = compute_class_weight(class_weight=\"balanced\", classes=classes_orig, y=y_train.dropna())\n",
    "                class_weight_map = {c: float(w) for c, w in zip(classes_orig, cls_w)}\n",
    "            except Exception:\n",
    "                class_weight_map = {c: 1.0 for c in classes_orig}\n",
    "            if 1 in class_weight_map:\n",
    "                class_weight_map[1] *= 1.3\n",
    "\n",
    "            # sample weights aligned with original y_train\n",
    "            sample_weight = y_train.map(lambda v: class_weight_map.get(v, 1.0)).values\n",
    "\n",
    "            # Encode labels to 0..K-1 for XGBoost & calibration\n",
    "            le = LabelEncoder()\n",
    "            # fit on train labels (dropna). We must handle NaNs if present - drop rows with NaN labels in training\n",
    "            notna_train = y_train.notna()\n",
    "            X_train_enc = X_train.loc[notna_train]\n",
    "            y_train_enc = y_train.loc[notna_train].astype(int)\n",
    "            y_train_le = le.fit_transform(y_train_enc)\n",
    "            # rebuild sample_weight to match encoded rows\n",
    "            sample_weight_enc = y_train.loc[notna_train].map(lambda v: class_weight_map.get(v, 1.0)).values\n",
    "\n",
    "            n_classes = len(le.classes_)\n",
    "            if n_classes < 2:\n",
    "                logging.warning(f\"Not enough classes in training for horizon {h} block {bid}; skipping\")\n",
    "                continue\n",
    "\n",
    "            # construct classifier with explicit multiclass objective/num_class\n",
    "            clf = xgb.XGBClassifier(**HYPER, objective=\"multi:softprob\", num_class=n_classes)\n",
    "            clf.fit(X_train_enc, y_train_le, sample_weight=sample_weight_enc)\n",
    "\n",
    "            # Calibration\n",
    "            if len(X_train_enc) < 50:\n",
    "                calibrated = clf\n",
    "                calibrator_name = \"none\"\n",
    "            else:\n",
    "                X_tr, X_cal, y_tr_enc, y_cal_enc = train_test_split(\n",
    "                    X_train_enc, y_train_le, test_size=0.1, random_state=SEED, stratify=y_train_le\n",
    "                )\n",
    "                clf_inner = xgb.XGBClassifier(**HYPER, objective=\"multi:softprob\", num_class=n_classes)\n",
    "                sw_tr = pd.Series(y_tr_enc).map(lambda enc: 1.0).values  # we already used class weights earlier; optional\n",
    "                clf_inner.fit(X_tr, y_tr_enc)\n",
    "\n",
    "                best_cal = None\n",
    "                best_score = float(\"inf\")\n",
    "                for method in [\"sigmoid\", \"isotonic\"]:\n",
    "                    try:\n",
    "                        cal = CalibratedClassifierCV(clf_inner, cv=\"prefit\", method=method)\n",
    "                        cal.fit(X_cal, y_cal_enc)\n",
    "                        probs_cal = cal.predict_proba(X_cal)\n",
    "                        eps = 1e-15\n",
    "                        ll = -np.mean(np.log(np.maximum(eps, probs_cal[np.arange(len(y_cal_enc)), y_cal_enc])))\n",
    "                        if ll < best_score:\n",
    "                            best_score = ll\n",
    "                            best_cal = (method, cal)\n",
    "                    except Exception as e:\n",
    "                        logging.debug(f\"Calibration method {method} failed: {e}\")\n",
    "\n",
    "                if best_cal is None:\n",
    "                    calibrated = clf_inner\n",
    "                    calibrator_name = \"none\"\n",
    "                else:\n",
    "                    calibrator_name, calibrated = best_cal\n",
    "\n",
    "            # Prepare test labels encoded (only for rows where label not NaN)\n",
    "            test_notna = y_test.notna()\n",
    "            X_test_enc = X_test.loc[test_notna]\n",
    "            y_test_orig = y_test.loc[test_notna].astype(int)\n",
    "            # If some classes in test were unseen by train, label encoder can't transform them -> handle by mapping where possible\n",
    "            # For simplicity, map only values present in le.classes_\n",
    "            mapping_orig_to_enc = {orig: enc for enc, orig in enumerate(le.classes_)}\n",
    "            y_test_enc = []\n",
    "            keep_idx = []\n",
    "            for i, v in enumerate(y_test_orig.values):\n",
    "                if v in mapping_orig_to_enc:\n",
    "                    y_test_enc.append(mapping_orig_to_enc[v])\n",
    "                    keep_idx.append(i)\n",
    "                else:\n",
    "                    # skip rows with unseen label\n",
    "                    pass\n",
    "            if len(y_test_enc) == 0:\n",
    "                logging.warning(f\"No test rows have labels seen during train for horizon {h} block {bid}; skipping\")\n",
    "                continue\n",
    "            # align X_test_enc to rows we kept\n",
    "            X_test_enc = X_test_enc.iloc[keep_idx]\n",
    "            y_test_enc = np.array(y_test_enc)\n",
    "\n",
    "            # Predict probabilities on test\n",
    "            probs = calibrated.predict_proba(X_test_enc)\n",
    "            classes_order = list(calibrated.classes_)  # encoded classes\n",
    "\n",
    "            # find encoded indices corresponding to original 1 and -1 (if present)\n",
    "            encoded_up = mapping_orig_to_enc.get(1, None)\n",
    "            encoded_down = mapping_orig_to_enc.get(-1, None)\n",
    "            idx_up = classes_order.index(encoded_up) if (encoded_up is not None and encoded_up in classes_order) else None\n",
    "            idx_down = classes_order.index(encoded_down) if (encoded_down is not None and encoded_down in classes_order) else None\n",
    "\n",
    "            if idx_up is None or idx_down is None:\n",
    "                logging.warning(f\"Classes 1 or -1 missing in model.classes_ for horizon {h} block {bid}\")\n",
    "\n",
    "            def compute_neutral_fraction(tau, probs_arr, idx_u, idx_d):\n",
    "                if idx_u is None or idx_d is None:\n",
    "                    return 0.0\n",
    "                p_up = probs_arr[:, idx_u]\n",
    "                p_down = probs_arr[:, idx_d]\n",
    "                dominant = np.maximum(p_up, p_down)\n",
    "                neutral = dominant < tau\n",
    "                return float(neutral.mean())\n",
    "\n",
    "            lo, hi = targets[h]\n",
    "            taus = np.linspace(0.5, 0.95, 91)\n",
    "            best_tau = None\n",
    "            best_gap = float(\"inf\")\n",
    "            for t in taus:\n",
    "                frac = compute_neutral_fraction(t, probs, idx_up, idx_down)\n",
    "                if lo <= frac <= hi:\n",
    "                    best_tau = float(t)\n",
    "                    break\n",
    "                gap = min(abs(frac - lo), abs(frac - hi))\n",
    "                if gap < best_gap:\n",
    "                    best_gap = gap\n",
    "                    best_tau = float(t)\n",
    "\n",
    "            thresholds[h] = best_tau if thresholds[h] is None else thresholds[h]\n",
    "\n",
    "            # Decision on test (use probs from calibrated and encoded indices)\n",
    "            if idx_up is None or idx_down is None:\n",
    "                y_pred_enc = calibrated.predict(X_test_enc)\n",
    "            else:\n",
    "                p_up_test = probs[:, idx_up]\n",
    "                p_down_test = probs[:, idx_down]\n",
    "                y_pred_enc = np.where(np.maximum(p_up_test, p_down_test) < best_tau,  # neutral\n",
    "                                      -999,  # temporary marker\n",
    "                                      np.where(p_up_test > p_down_test, encoded_up, encoded_down))\n",
    "\n",
    "                # map -999 (neutral) to encoded class for neutral: we need to choose an encoded label for neutral (there is none)\n",
    "                # we'll decode encoded preds back to original domain by mapping encoded_up->1, encoded_down->-1, neutral->0\n",
    "                # create y_pred_orig accordingly\n",
    "                y_pred_orig = []\n",
    "                for val in y_pred_enc:\n",
    "                    if val == -999:\n",
    "                        y_pred_orig.append(0)\n",
    "                    elif val == encoded_up:\n",
    "                        y_pred_orig.append(1)\n",
    "                    elif val == encoded_down:\n",
    "                        y_pred_orig.append(-1)\n",
    "                    else:\n",
    "                        # fallback decode if possible\n",
    "                        decoded = le.inverse_transform([val])[0] if val in range(len(le.classes_)) else 0\n",
    "                        y_pred_orig.append(int(decoded))\n",
    "                # prepare y_test_orig_aligned for metric computation\n",
    "                y_test_orig_aligned = y_test_orig.iloc[keep_idx].values\n",
    "                y_pred = np.array(y_pred_orig)\n",
    "            # If idx missing and we used predict, decode encoded predictions back to original labels\n",
    "            if (idx_up is None or idx_down is None):\n",
    "                # decode encoded predictions\n",
    "                y_pred = le.inverse_transform(y_pred_enc)\n",
    "\n",
    "                # The test labels to compare need to be decoded similarly:\n",
    "                y_test_orig_aligned = y_test_enc  # these are encoded; decode\n",
    "                y_test_orig_aligned = le.inverse_transform(y_test_enc)\n",
    "\n",
    "            # compute metrics on original label space (-1,0,1 expected)\n",
    "            acc_bal = balanced_accuracy_score(y_test_orig_aligned, y_pred)\n",
    "            try:\n",
    "                mcc = matthews_corrcoef(y_test_orig_aligned, y_pred)\n",
    "            except Exception:\n",
    "                mcc = float(\"nan\")\n",
    "            f1_up = f1_score(y_test_orig_aligned, y_pred, labels=[1], average=\"macro\", zero_division=0)\n",
    "            f1_down = f1_score(y_test_orig_aligned, y_pred, labels=[-1], average=\"macro\", zero_division=0)\n",
    "\n",
    "            metrics_rows.append(\n",
    "                {\n",
    "                    \"horizon\": h,\n",
    "                    \"block_id\": bid,\n",
    "                    \"acc_bal\": float(acc_bal),\n",
    "                    \"mcc_macro\": float(mcc),\n",
    "                    \"f1_up\": float(f1_up),\n",
    "                    \"f1_down\": float(f1_down),\n",
    "                    \"n_test\": int(len(y_test_orig_aligned)),\n",
    "                    \"calibrator\": calibrator_name,\n",
    "                    \"tau_used\": best_tau,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Optional calibration curve for 'up' class\n",
    "            try:\n",
    "                if idx_up is not None:\n",
    "                    p_up = probs[:, idx_up]\n",
    "                    frac_pos, mean_pred = calibration_curve((y_test_orig_aligned == 1).astype(int), p_up, n_bins=10)\n",
    "                    plt.figure()\n",
    "                    plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "                    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"k\")\n",
    "                    plt.xlabel(\"Mean predicted prob (up)\")\n",
    "                    plt.ylabel(\"Fraction of positives\")\n",
    "                    plt.title(f\"Calibration up: h{h} block{bid}\")\n",
    "                    png = GOLD_DIR / f\"calibration_curve_d{h}_block{bid}.png\"\n",
    "                    plt.savefig(png)\n",
    "                    plt.close()\n",
    "            except Exception as e:\n",
    "                logging.debug(f\"Calibration plot failed: {e}\")\n",
    "\n",
    "    # save metrics and thresholds\n",
    "    pd.DataFrame(metrics_rows).to_csv(METRICS_CSV, index=False)\n",
    "    with THRESHOLDS_JSON.open(\"w\") as f:\n",
    "        json.dump({f\"d{h}\": thresholds[h] for h in thresholds}, f, indent=2)\n",
    "    logging.info(f\"Metrics saved: {METRICS_CSV}\")\n",
    "    logging.info(f\"Thresholds saved: {THRESHOLDS_JSON}\")\n",
    "\n",
    "    # append provenance\n",
    "    prov_summary = {\n",
    "        \"seed\": SEED,\n",
    "        \"partitions\": str(PARTITIONS_CSV),\n",
    "        \"hyperparameters\": HYPER,\n",
    "        \"class_weighting_note\": \"positive class weight multiplied by 1.3 if present\",\n",
    "        \"metrics_file\": str(METRICS_CSV),\n",
    "        \"thresholds_file\": str(THRESHOLDS_JSON),\n",
    "        \"gold_parquet_sha256\": sha256_of_file(GOLD_PARQUET) if GOLD_PARQUET.exists() else None,\n",
    "        \"outputs_mtime\": {\n",
    "            \"metrics\": METRICS_CSV.stat().st_mtime if METRICS_CSV.exists() else None,\n",
    "            \"thresholds\": THRESHOLDS_JSON.stat().st_mtime if THRESHOLDS_JSON.exists() else None,\n",
    "        },\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"python\": sys.version,\n",
    "        \"platform\": platform.platform(),\n",
    "    }\n",
    "    line = f\"[{datetime.now().isoformat()}] BASELINE_XGB: {json.dumps(prov_summary, default=str)}\\n\"\n",
    "    PROV.write_text(PROV.read_text() + line if PROV.exists() else line)\n",
    "    logging.info(f\"Provenance appended: {PROV}\")\n",
    "\n",
    "def main():\n",
    "    df = load_gold(GOLD_PARQUET)\n",
    "    feat_map = select_features(df)\n",
    "    partitions = make_partitions(df, n_splits=5)\n",
    "    train_and_evaluate(df, feat_map, partitions)\n",
    "\n",
    "# Execute\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8784354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partition/class diagnostics...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, prow \u001b[38;5;129;01min\u001b[39;00m parts.iterrows():\n\u001b[32m     18\u001b[39m     bid = \u001b[38;5;28mint\u001b[39m(prow[\u001b[33m'\u001b[39m\u001b[33mblock_id\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     19\u001b[39m     train_mask = (\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         (pd.to_datetime(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]).dt.date >= pd.to_datetime(prow[\u001b[33m'\u001b[39m\u001b[33mtrain_start\u001b[39m\u001b[33m'\u001b[39m]).date())\n\u001b[32m     21\u001b[39m         & (pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]).dt.date <= pd.to_datetime(prow[\u001b[33m'\u001b[39m\u001b[33mtrain_end\u001b[39m\u001b[33m'\u001b[39m]).date())\n\u001b[32m     22\u001b[39m     )\n\u001b[32m     23\u001b[39m     test_mask = (\n\u001b[32m     24\u001b[39m         (pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]).dt.date >= pd.to_datetime(prow[\u001b[33m'\u001b[39m\u001b[33mtest_start\u001b[39m\u001b[33m'\u001b[39m]).date())\n\u001b[32m     25\u001b[39m         & (pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m]).dt.date <= pd.to_datetime(prow[\u001b[33m'\u001b[39m\u001b[33mtest_end\u001b[39m\u001b[33m'\u001b[39m]).date())\n\u001b[32m     26\u001b[39m     )\n\u001b[32m     27\u001b[39m     row = {\u001b[33m'\u001b[39m\u001b[33mblock_id\u001b[39m\u001b[33m'\u001b[39m: bid, \u001b[33m'\u001b[39m\u001b[33mtrain_rows\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(train_mask.sum()), \u001b[33m'\u001b[39m\u001b[33mtest_rows\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(test_mask.sum())}\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Diagnóstico de classes por partição\n",
    "# Cola esta célula no final do notebook e execute após ter carregado/definido `df`, `PARTITIONS_CSV` e a função `make_partitions`.\n",
    "# O objetivo: mostrar por bloco e por horizonte a distribuição de rótulos no conjunto de treino/teste\n",
    "# e sugerir uma alternativa de particionamento (por exemplo n_splits=4) caso haja blocos com poucas classes.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print('Running partition/class diagnostics...')\n",
    "\n",
    "if not Path(PARTITIONS_CSV).exists():\n",
    "    print(f'Partitions CSV not found: {PARTITIONS_CSV} — execute make_partitions(df, n_splits=5) first')\n",
    "else:\n",
    "    parts = pd.read_csv(PARTITIONS_CSV)\n",
    "    parts_display = []\n",
    "    issues = []\n",
    "    for _, prow in parts.iterrows():\n",
    "        bid = int(prow['block_id'])\n",
    "        train_mask = (\n",
    "            (pd.to_datetime(df['date']).dt.date >= pd.to_datetime(prow['train_start']).date())\n",
    "            & (pd.to_datetime(df['date']).dt.date <= pd.to_datetime(prow['train_end']).date())\n",
    "        )\n",
    "        test_mask = (\n",
    "            (pd.to_datetime(df['date']).dt.date >= pd.to_datetime(prow['test_start']).date())\n",
    "            & (pd.to_datetime(df['date']).dt.date <= pd.to_datetime(prow['test_end']).date())\n",
    "        )\n",
    "        row = {'block_id': bid, 'train_rows': int(train_mask.sum()), 'test_rows': int(test_mask.sum())}\n",
    "        for h in (1, 3, 5):\n",
    "            col = f'y_d{h}_cls'\n",
    "            if col not in df.columns:\n",
    "                row[f'train_unique_d{h}'] = None\n",
    "                row[f'test_unique_d{h}'] = None\n",
    "                row[f'train_counts_d{h}'] = ''\n",
    "                row[f'test_counts_d{h}'] = ''\n",
    "                continue\n",
    "            train_counts = df.loc[train_mask, col].value_counts(dropna=True).to_dict()\n",
    "            test_counts = df.loc[test_mask, col].value_counts(dropna=True).to_dict()\n",
    "            row[f'train_unique_d{h}'] = len(train_counts)\n",
    "            row[f'test_unique_d{h}'] = len(test_counts)\n",
    "            row[f'train_counts_d{h}'] = str(train_counts)\n",
    "            row[f'test_counts_d{h}'] = str(test_counts)\n",
    "\n",
    "            # detect small-class issues: fewer than 2 classes or any class with < 5 samples\n",
    "            if row[f'train_unique_d{h}'] < 2:\n",
    "                issues.append((bid, h, 'few_classes_train'))\n",
    "            else:\n",
    "                if any(v < 5 for v in train_counts.values()):\n",
    "                    issues.append((bid, h, 'small_class_count'))\n",
    "\n",
    "        parts_display.append(row)\n",
    "\n",
    "    df_parts = pd.DataFrame(parts_display).sort_values('block_id')\n",
    "    pd.set_option('display.max_colwidth', 200)\n",
    "    print('\\nPartition overview:')\n",
    "    display(df_parts)\n",
    "\n",
    "    if not issues:\n",
    "        print('\\nNo immediate class-balance/coverage issues detected.')\n",
    "    else:\n",
    "        print('\\nDetected issues (block_id, horizon, problem):')\n",
    "        for it in issues:\n",
    "            print(' -', it)\n",
    "\n",
    "        # Simple suggestion heuristics\n",
    "        # If many blocks have issues, propose fewer splits (e.g., n_splits=4)\n",
    "        n_issues = len({(b, h) for b, h, _ in issues})\n",
    "        if n_issues >= 2:\n",
    "            print('\\nSuggestion: several blocks have insufficient classes. Try reducing the number of splits (e.g. n_splits=4)')\n",
    "            try:\n",
    "                proposed = make_partitions(df, n_splits=4)\n",
    "                outp = Path(PARTITIONS_CSV).with_name('partitions_proposed_k4.csv')\n",
    "                proposed.to_csv(outp, index=False)\n",
    "                print(f'Proposed partitions (n_splits=4) saved to: {outp}')\n",
    "                display(proposed)\n",
    "            except Exception as e:\n",
    "                print('Could not generate proposed partitions automatically:', e)\n",
    "        else:\n",
    "            print('\\nSuggestion: for the affected blocks you can:')\n",
    "            print(' - expand the training window (increase train_end for previous block)')\n",
    "            print(' - merge the affected block with adjacent block(s)')\n",
    "            print(' - reduce embargo (if safe from leakage) to increase available train data')\n",
    "            print('\\nExample: to quickly try fewer splits call:')\n",
    "            print('  proposed = make_partitions(df, n_splits=4)')\n",
    "            print('  proposed.to_csv(Path(PARTITIONS_CSV).with_name(\"partitions_proposed_k4.csv\"), index=False)')\n",
    "\n",
    "print('\\nDiagnostics complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527b8f28",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Arquivo de partições proposto não encontrado: /home/wrm/BOLSA_2026/gold/IBOV/partitions_proposed_k4.csv — execute a célula de diagnóstico primeiro",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m proposed_csv = Path(PARTITIONS_CSV).with_name(\u001b[33m'\u001b[39m\u001b[33mpartitions_proposed_k4.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proposed_csv.exists():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mArquivo de partições proposto não encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproposed_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m — execute a célula de diagnóstico primeiro\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# ajusta nomes de saída locais com sufixo\u001b[39;00m\n\u001b[32m     17\u001b[39m METRICS_K4 = Path(METRICS_CSV).with_name(Path(METRICS_CSV).stem + SUFFIX + Path(METRICS_CSV).suffix)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Arquivo de partições proposto não encontrado: /home/wrm/BOLSA_2026/gold/IBOV/partitions_proposed_k4.csv — execute a célula de diagnóstico primeiro"
     ]
    }
   ],
   "source": [
    "# Re-run baseline usando partitions_proposed_k4.csv e salvar artefatos com sufixo _k4\n",
    "# Use esta célula após ter executado a célula de diagnóstico que salva `partitions_proposed_k4.csv`.\n",
    "# Ela carrega o parquet GOLD_PARQUET, a partição proposta e executa train_and_evaluate,\n",
    "# salvando métricas/thresholds/provenance com sufixo _k4 para comparação.\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "\n",
    "SUFFIX = \"_k4\"\n",
    "proposed_csv = Path(PARTITIONS_CSV).with_name('partitions_proposed_k4.csv')\n",
    "if not proposed_csv.exists():\n",
    "    raise FileNotFoundError(f'Arquivo de partições proposto não encontrado: {proposed_csv} — execute a célula de diagnóstico primeiro')\n",
    "\n",
    "# ajusta nomes de saída locais com sufixo\n",
    "METRICS_K4 = Path(METRICS_CSV).with_name(Path(METRICS_CSV).stem + SUFFIX + Path(METRICS_CSV).suffix)\n",
    "THRESHOLDS_K4 = Path(THRESHOLDS_JSON).with_name(Path(THRESHOLDS_JSON).stem + SUFFIX + Path(THRESHOLDS_JSON).suffix)\n",
    "PROV_K4 = PROV.with_name(PROV.stem + SUFFIX + PROV.suffix)\n",
    "\n",
    "# Carrega dados e partições propostas\n",
    "print('Loading gold parquet and proposed partitions...')\n",
    "df = load_gold(GOLD_PARQUET)\n",
    "partitions_prop = pd.read_csv(proposed_csv)\n",
    "\n",
    "# Função wrapper que escreve para arquivos sufixados\n",
    "def train_and_evaluate_k4(df, feat_map, partitions):\n",
    "    # reusa a função original train_and_evaluate mas captura seus resultados\n",
    "    # para não duplicar lógica, chamamos a função existente e depois renomeamos os arquivos salvos\n",
    "    train_and_evaluate(df, feat_map, partitions)\n",
    "    # os arquivos originais foram escritos em METRICS_CSV e THRESHOLDS_JSON; renomeie/copiar para _k4\n",
    "    import shutil\n",
    "    if Path(METRICS_CSV).exists():\n",
    "        shutil.copy2(METRICS_CSV, METRICS_K4)\n",
    "        logging.info(f'Copied metrics -> {METRICS_K4}')\n",
    "    if Path(THRESHOLDS_JSON).exists():\n",
    "        shutil.copy2(THRESHOLDS_JSON, THRESHOLDS_K4)\n",
    "        logging.info(f'Copied thresholds -> {THRESHOLDS_K4}')\n",
    "    # append provenance indicating this was a k4 run\n",
    "    prov_line = f\"[{pd.Timestamp.now().isoformat()}] BASELINE_XGB_K4: partitions={proposed_csv}, metrics={METRICS_K4}, thresholds={THRESHOLDS_K4}\\n\"\n",
    "    PROV_K4.write_text(PROV_K4.read_text() + prov_line if PROV_K4.exists() else prov_line)\n",
    "    logging.info(f'Provenance appended: {PROV_K4}')\n",
    "\n",
    "# Execute\n",
    "feat_map = select_features(df)\n",
    "print('Starting train_and_evaluate with proposed partitions (k=4)...')\n",
    "train_and_evaluate_k4(df, feat_map, partitions_prop)\n",
    "print('Finished. Outputs:')\n",
    "print(' - metrics:', METRICS_K4)\n",
    "print(' - thresholds:', THRESHOLDS_K4)\n",
    "print(' - provenance:', PROV_K4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project: BOLSA_2026)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
